{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Francesca Tuazon (BCS34)\n",
        "\n",
        "**Problem Statement**: You are tasked with exploring the behavior of n-gram models in text generation. Specifically, you need to:\n",
        "\n",
        "- *Implement an n-gram Model*: Build a Python program that constructs an n-gram model from a given sample text. The program should handle various values of n to create models ranging from bigrams to higher-order n-grams.\n",
        "\n",
        "- *Generate Text with Different Inputs*: Use the n-gram model to generate text based on different sample inputs. Compare the generated text for various n-values and observe how the choice of n and input text affects the output.\n",
        "\n",
        "- *Analyze the Results*: Examine the coherence and relevance of the generated text. Identify any patterns or issues related to different n-gram sizes and sample texts. Assess how well the generated text reflects the structure and style of the input text.\n",
        "\n",
        "**Tasks**:\n",
        "- *Create an n-gram Model*: Implement a Python script that builds an n-gram model from a provided text. The script should handle varying sizes of n-grams (e.g., bigrams, trigrams, and 4-grams).\n",
        "- *Generate and Compare Texts*: Use the model to generate text sequences for different input texts. Experiment with different n-values and analyze how these affect the text output. Example inputs could be:\n",
        "  - Text 1: \"The quick brown fox jumps over the lazy dog.\"\n",
        "  - Text 2: \"Data science is an interdisciplinary field that uses scientific methods.\"\n",
        "  - Generate text sequences with various n-values (e.g., trigram, and 4-gram) for each input text.\n",
        "- *Evaluate and Discuss*: Compare the quality of the generated text across different n-values. Consider aspects such as coherence, relevance, and adherence to the input text's style.\n",
        "  - Discuss any observed patterns or anomalies in the generated text and suggest potential improvements to the n-gram model or text generation process."
      ],
      "metadata": {
        "id": "kl5iH1-O4wCz"
      }
    },
    {
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sample text for n-gram generation\n",
        "text = {\n",
        "    \"It is only with the heart that one can see rightly; what is essential is invisible to the eye.\",\n",
        "    \"It is the time you have wasted for your rose that makes your rose so important.\",\n",
        "    \"I am looking for friends. What does that mean -- tame?\",\n",
        "    \"If you love a flower that lives on a star, it is sweet to look at the sky at night.\",\n",
        "    \"You see, one loves the sunset when one is so sad.\",\n",
        "    \"To me, you will be unique in all the world. To you, I shall be unique in all the world.\",\n",
        "    \"The land of tears is so mysterious.\"\n",
        "}\n",
        "\n",
        "# Create a bigram model\n",
        "n = 2\n",
        "ngrams = defaultdict(list)\n",
        "\n",
        "# Convert the set of strings to a single string\n",
        "all_text = \" \".join(text)  # Join all sentences in the set into a single string\n",
        "\n",
        "# Split the string into words\n",
        "words = all_text.split()\n",
        "\n",
        "for i in range(len(words) - n + 1):\n",
        "    gram = tuple(words[i:i+n])\n",
        "    next_word = words[i+n] if i+n < len(words) else None\n",
        "    if next_word: # Only add next_word if it's not None\n",
        "        ngrams[gram].append(next_word)\n",
        "\n",
        "#Get user input\n",
        "user_input = input(\"Enter a word or phrase: \")\n",
        "input_words = user_input.split()\n",
        "\n",
        "#Find matching grams\n",
        "matching_grams = [gram for gram in ngrams if gram[-1] == input_words[-1]]\n",
        "\n",
        "if matching_grams:\n",
        "    current_gram = random.choice(matching_grams)\n",
        "    result = list(current_gram)\n",
        "\n",
        "    #autocomplete suggestions\n",
        "    for _ in range(10):\n",
        "      if current_gram in ngrams and ngrams[current_gram]:\n",
        "        next_word = random.choice(ngrams[current_gram])\n",
        "        result.append(next_word)\n",
        "        current_gram = tuple(result[-n:])\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    print(\"Autocomplete suggestion: : \", \" \".join(result))\n",
        "else:\n",
        "  print(\"No matching grams found\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRd8KLevm_oC",
        "outputId": "4a6029da-7ea3-4bf5-f90b-66ac3f7d0ce4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word or phrase: it is\n",
            "Autocomplete suggestion: :  It is the time you have wasted for your rose that makes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def build_ngram_model(text, n):\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    model = defaultdict(list)\n",
        "    for i in range(len(words) - n + 1):\n",
        "        gram = tuple(words[i:i + n])\n",
        "        next_word = words[i + n] if i + n < len(words) else None\n",
        "        if next_word:\n",
        "            model[gram[:-1]].append(next_word)\n",
        "    return model\n",
        "\n",
        "def generate_text(model, start_words, num_words):\n",
        "    current_gram = tuple(start_words)\n",
        "    result = list(start_words)\n",
        "    for _ in range(num_words - len(start_words)):\n",
        "        if current_gram in model:\n",
        "            next_word = random.choice(model[current_gram])\n",
        "            result.append(next_word)\n",
        "            current_gram = tuple(result[-len(current_gram):])\n",
        "        else:\n",
        "            break\n",
        "    return \" \".join(result)\n",
        "\n",
        "def main():\n",
        "    texts = [\n",
        "        \"It is only with the heart that one can see rightly.\",\n",
        "        \"It is the time you have wasted for your rose that makes your rose so important.\",\n",
        "        \"I am looking for friends. What does that mean -- tame?\",\n",
        "        \"If you love a flower that lives on a star, it is sweet to look at the sky at night.\",\n",
        "        \"You see, one loves the sunset when one is so sad.\",\n",
        "        \"To me, you will be unique in all the world. To you, I shall be unique in all the world.\",\n",
        "        \"The land of tears is so mysterious.\"\n",
        "    ]\n",
        "\n",
        "    n_values = [2, 3, 4]\n",
        "\n",
        "    for text in texts:\n",
        "        print(f\"\\nInput text: {text}\")\n",
        "        for n in n_values:\n",
        "            model = build_ngram_model(text, n)\n",
        "            start_words = re.findall(r'\\b\\w+\\b', text.lower())[:n-1]  # Use the first n-1 words as start\n",
        "            if start_words:\n",
        "              generated_text = generate_text(model, start_words, 20)\n",
        "              print(f\"{n}-gram generated text: {generated_text}\")\n",
        "            else:\n",
        "              print(f\"Not enough words to generate {n}-grams\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA6srbiBnZZB",
        "outputId": "89c99942-6407-4807-f324-216a1c5d43fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input text: It is only with the heart that one can see rightly.\n",
            "2-gram generated text: it only the that can rightly\n",
            "3-gram generated text: it is with\n",
            "4-gram generated text: it is only the\n",
            "\n",
            "Input text: It is the time you have wasted for your rose that makes your rose so important.\n",
            "2-gram generated text: it the you wasted your that your that your that your so\n",
            "3-gram generated text: it is time\n",
            "4-gram generated text: it is the you\n",
            "\n",
            "Input text: I am looking for friends. What does that mean -- tame?\n",
            "2-gram generated text: i looking friends does mean\n",
            "3-gram generated text: i am for\n",
            "4-gram generated text: i am looking friends\n",
            "\n",
            "Input text: If you love a flower that lives on a star, it is sweet to look at the sky at night.\n",
            "2-gram generated text: if love flower lives a it sweet look the at sky night\n",
            "3-gram generated text: if you a\n",
            "4-gram generated text: if you love flower\n",
            "\n",
            "Input text: You see, one loves the sunset when one is so sad.\n",
            "2-gram generated text: you one the when is sad\n",
            "3-gram generated text: you see loves\n",
            "4-gram generated text: you see one the\n",
            "\n",
            "Input text: To me, you will be unique in all the world. To you, I shall be unique in all the world.\n",
            "2-gram generated text: to i be in the to you be in the to you be in the to you shall unique all\n",
            "3-gram generated text: to me will\n",
            "4-gram generated text: to me you be\n",
            "\n",
            "Input text: The land of tears is so mysterious.\n",
            "2-gram generated text: the of is mysterious\n",
            "3-gram generated text: the land tears\n",
            "4-gram generated text: the land of is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "The first code block shows the autocomplete suggestion based on the user's input, while the second code block dissects each text into the n-gram generated text, helping us visualize how the prior block works in returning its results.\n",
        "\n",
        "The quality of the autocomplete suggestion varies significantly with the value of **n**.  By dissecting the text into n-grams, we gain insight into how the model forms its predictions. The lower the n values, the less coherent the text due to the limitations in context. However, higher n-values can also introduce repetition and unusual phrases."
      ],
      "metadata": {
        "id": "TQG_JYQi3mYR"
      }
    }
  ]
}